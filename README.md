# üß† Reposit√≥rio da Disciplina: Redes Neurais e Aprendizado Profundo

![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat-square&logo=numpy&logoColor=white)

## Sobre o Reposit√≥rio

Este reposit√≥rio cont√©m todos os trabalhos pr√°ticos, anota√ß√µes e projetos desenvolvidos para a disciplina de Redes Neurais e Aprendizado Profundo. O objetivo √© aplicar os conceitos te√≥ricos aprendidos em aula na constru√ß√£o de modelos de Machine Learning e Deep Learning.

---

### Informa√ß√µes da Disciplina

* **Universidade:** Universidade Federal de Vi√ßosa - Campus Florestal
* **Curso:** Ci√™ncia da Computa√ß√£o
* **Professor(a):** Jose Augusto Miranda Nacif

---

## üöÄ Trabalhos Pr√°ticos

Esta se√ß√£o documenta o progresso e as entregas dos trabalhos pr√°ticos da disciplina.

### üìÑ [Trabalho 01: Regress√£o Log√≠stica para Classifica√ß√£o de Imagens](./TP01-Regressao-Logistica/)

* **Objetivo:** Implementar um algoritmo de Regress√£o Log√≠stica do zero, usando apenas NumPy, para resolver um problema de classifica√ß√£o bin√°ria de imagens (Gato vs. N√£o-Gato).
* **Status:** `Conclu√≠do ‚úîÔ∏è`
* **Conceitos Chave Aplicados:**
    * Pr√©-processamento de imagens (achatar e normalizar).
    * Implementa√ß√£o da Fun√ß√£o Sigmoide.
    * C√°lculo da Fun√ß√£o de Custo (Entropia Cruzada Bin√°ria).
    * Implementa√ß√£o do Gradiente Descendente para otimiza√ß√£o dos pesos.

### üìÑ [TP 02: Multilayer Perceptron e Backpropagation](./TP02-Backpropagation/)

* **Objetivo:** Construir uma rede neural de m√∫ltiplas camadas (MLP) com um n√∫mero flex√≠vel de camadas. O foco principal √© a implementa√ß√£o do algoritmo de Backpropagation para treinar a rede e melhorar a acur√°cia em rela√ß√£o ao modelo de Regress√£o Log√≠stica.
* **Status:** `Conclu√≠do ‚úîÔ∏è`
* **Entrega:** 30/09
* **Conceitos Chave Aplicados:**
    * Implementa√ß√£o de Rede Neural Profunda (MLP).
    * Algoritmo de Backpropagation (retropropaga√ß√£o de erro).
    * Fun√ß√£o de Ativa√ß√£o ReLU para camadas ocultas.
    * Inicializa√ß√£o de pesos avan√ßada.
    * Avalia√ß√£o de modelo com Acur√°cia, Precis√£o, Revoca√ß√£o e Matriz de Confus√£o.

### üìù TP 03: Redes Neurais Convolucionais

* **Objetivo:** `(A ser preenchido)`
* **Status:** `A Fazer ‚è≥`
* **Entrega:** 21/10

### üìù TP 04: Redes Neurais Recursivas

* **Objetivo:** `(A ser preenchido)`
* **Status:** `A Fazer ‚è≥`
* **Entrega:** 28/10

### üìù TPF-01: Reprodu√ß√£o de Artigo com Transformer

* **Objetivo:** Escolha e reprodu√ß√£o dos resultados de um artigo cient√≠fico que utiliza a arquitetura Transformer.
* **Status:** `A Fazer ‚è≥`
* **Entrega:** 04/11

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python
* **Bibliotecas Principais:** NumPy, Matplotlib, PIL, Scikit-learn
* **Ambiente de Desenvolvimento:** Google Colab
* **Controle de Vers√£o:** Git & GitHub

---

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/henrique-alves-5237862ab/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/alveshenriique)
